{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml-FYq-2DYLl"
   },
   "source": [
    "Here we do time series anomaly detection using Facebook (Meta) Prophet (https://facebook.github.io/prophet/) model in Python. Anomalies are also called outliers, and we will use these two terms interchangeably. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9JY8l2BUnq8"
   },
   "source": [
    "# Step 0: Algorithm for Time Series Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92QexYZDWrf4"
   },
   "source": [
    "In step 0, let's talk about the algorithm for time series anomaly detection. At a high level, the outliers are detected based on the prediction interval of the time series. The implementation includes the following steps:\n",
    "\n",
    "1. Build a time series forecasting model.\n",
    "2. Make predictions on historical data using the time series forecasting model.\n",
    "3. Compare the actual values with the prediction intervals. Outliers are defined as the data points with actual values outside of the prediction intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfPJby-2E_II"
   },
   "source": [
    "# Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cE2gt2RVPiu"
   },
   "source": [
    "we will install and import libraries.\n",
    "\n",
    "`prophet` is the package for the time series model. Afterwards `prophet` is imported into the notebook. \n",
    "\n",
    "We also import `pandas` and `numpy` for data processing, `seaborn` and `matplotlib` for visualization, and `mean_absolute_error` and `mean_absolute_percentage_error` for the model performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaAXOq7cFUCx"
   },
   "outputs": [],
   "source": [
    "# Prophet model for time series forecast\n",
    "from prophet import Prophet\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model performance evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S3-Wup8FVRK"
   },
   "source": [
    "# Step 2: Get Data and processes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"../../../data/raw/Time_Series_Merchants_Transactions_Anonymized.csv\"\n",
    "df_merchant_transactions = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merchant_transactions = df_merchant_transactions.drop(columns='Merchant Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-08'\n",
    "end_date = '2022-10'\n",
    "# replacing columns names with standard date format\n",
    "stddates = pd.date_range(start=start_date, end=end_date, freq=\"M\")\n",
    "df_merchant_transactions.columns = stddates\n",
    "df_merchant_transactions.head()\n",
    "#stddates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP1HYiU4csi9"
   },
   "source": [
    "The goal of the time series model is to predict the six group merchant transactions.\n",
    "\n",
    "Prophet requires at least two columns as inputs: a `ds` column and a `y` column.\n",
    "* The `ds` column has the time information. Currently we have the date as the index, so we name this index as `ds`.\n",
    "* The y column has the time series transaction values. In this example, because we are predicting six group merchant transactions, the column name for the transactions is named `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1654516585334,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "zV_isB1rixMM",
    "outputId": "495774a1-ca1b-40b1-bd8e-a6673d4e3bae"
   },
   "outputs": [],
   "source": [
    "df= {'ds':stddates,\n",
    "    'y' :df_merchant_transactions.iloc[0,:].values\n",
    "    }\n",
    "data = pd.DataFrame(df)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BapqA5emxQhr"
   },
   "source": [
    "Using `.info`, we can see that the dataset has 26 records and there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1654516599240,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "CEpEZAhJPpaV",
    "outputId": "72a97cc5-fbf3-42f7-e0d4-04fe909fae0b"
   },
   "outputs": [],
   "source": [
    "# Information on the dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VinXfvMYnDna"
   },
   "source": [
    "Next, let's visualize the merchant transactions of the two tickers using `seaborn`, and add the legend to the plot using `matplotlib`. we see the transactions fluctuated over the given period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1654516628702,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "NhKMo4c-oU_8",
    "outputId": "5d1d3df8-0adc-4df6-a535-44126d501e9a"
   },
   "outputs": [],
   "source": [
    "# Visualize data using seaborn\n",
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.lineplot(x=data['ds'], y=data['y'])\n",
    "plt.legend(['merchant transactions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv4D-_sSoVHx"
   },
   "source": [
    "# Step 3: Build Time Series Model Using Prophet in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nbai1rbIxD4a"
   },
   "source": [
    "In step 3, we will build a time series model using Prophet in Python. \n",
    "\n",
    "Notice that we did not do train test split for the modeling dataset. This first goal is to fit a model that predicts well on the past prices. Therefore, we will use the whole dataset for both training and forecasting.\n",
    "\n",
    "* When initiating the prophet model, the seasonality_mode='multiplicative' is explicitly set, and then fit on the training data.\n",
    "* The `interval_width` is set to 0.99, which means that the uncertainty interval is 99%.\n",
    "\n",
    "We keep the model simple in this example to focus on the process of anomaly detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1654518895068,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "RZoayReeoYGu",
    "outputId": "82eb68ee-f55f-4f07-c21b-40c6c48798ff"
   },
   "outputs": [],
   "source": [
    "# Add seasonality\n",
    "model = Prophet(interval_width=0.99, seasonality_mode='multiplicative')\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbBJPgjlbX1p"
   },
   "source": [
    "# Step 4: Make Predictions Using Prophet in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5pt-y6vxg5C"
   },
   "source": [
    "After building the model, in step 4, we use the model to make predictions on the dataset. The forecast plot shows that the predictions are in general aligned with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1654518899718,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "idCZyhdexIJN",
    "outputId": "a36deab0-b2f7-4b46-8583-4d146a0c09e5"
   },
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "forecast = model.predict(data)\n",
    "\n",
    "# Visualize the forecast\n",
    "model.plot(forecast); # Add semi-colon to remove the duplicated chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylnS1AkqyGyo"
   },
   "source": [
    "We can also check the components plot for the trend, weekly seasonality, and yearly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1654518904105,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "8DMoBQnOzXX0",
    "outputId": "bff60ccb-3f0f-4cb7-a58b-000bebddb8d3"
   },
   "outputs": [],
   "source": [
    "# Visualize the forecast components\n",
    "model.plot_components(forecast);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLOvRvxmcKIc"
   },
   "source": [
    "# Step 5: Check Time Series Model Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2mOweX_cZa7"
   },
   "source": [
    "In step 5, we will check the time series model performance. The forecast dataframe does not include the actual values, so we need to merge the forecast dataframe with the actual dataframe to compare the actual values with the predicted values. Two performance metrics are included:\n",
    "\n",
    "* MAE (Mean Absolute Error) sums up the absolute difference between actual and prediction and is divided by the number of predictions.\n",
    "* MAPE (Mean Absolute Percentage Error) sums up the absolute percentage difference between actual and prediction and is divided by the number of predictions. MAPE is independent of the magnitude of data, so it can be used to compare different forecasts. But itâ€™s undefined when the actual value is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1654518907372,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "ddQWq-Jlz4Pl",
    "outputId": "2616a578-6171-4843-a9bf-bcbba01dcb2f"
   },
   "outputs": [],
   "source": [
    "# Merge actual and predicted values\n",
    "performance = pd.merge(data, forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "# Check MAE value\n",
    "performance_MAE = mean_absolute_error(performance['y'], performance['yhat'])\n",
    "print(f'The MAE for the model is {performance_MAE}')\n",
    "\n",
    "# Check MAPE value\n",
    "performance_MAPE = mean_absolute_percentage_error(performance['y'], performance['yhat'])\n",
    "print(f'The MAPE for the model is {performance_MAPE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKb28IpeyqQb"
   },
   "source": [
    "The mean absolute error (MAE) for the model is 373, meaning that on average, the forecast is off by 373. Given that transactions are in thousands, the prediction is not bad and better than Auto Arima and ETS.\n",
    "\n",
    "The mean absolute percent error (MAPE) for the baseline model is 7%, meaning that on average, the forecast is off by 7% of the transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liM3SW227N-b"
   },
   "source": [
    "# Step 6: Identify Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3lS7hpdnGqp"
   },
   "source": [
    "In step 6, we will identify the time series anomalies by checking if the actual value is outside of the uncertainty interval. If the actual value is smaller than the lower bound or larger than the upper bound of the uncertainty interval, the anomaly indicator is set to 1, otherwise, it's set to 0.\n",
    "\n",
    "Using `value_counts()`, we can see that there are no outliers out of 26 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1654518972094,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "BmchMZp77S7-",
    "outputId": "8161798e-5f6d-4713-e948-8eb8a2c413eb"
   },
   "outputs": [],
   "source": [
    "# Create an anomaly indicator\n",
    "performance['anomaly'] = performance.apply(lambda rows: 1 if ((rows.y<rows.yhat_lower)|(rows.y>rows.yhat_upper)) else 0, axis = 1)\n",
    "\n",
    "# Check the number of anomalies\n",
    "performance['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1654518974945,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "IbiUpzv979Qd",
    "outputId": "400dc6fe-8f9c-4673-b183-dc1326b7793a"
   },
   "outputs": [],
   "source": [
    "# Take a look at the anomalies\n",
    "anomalies = performance[performance['anomaly']==1].sort_values(by='ds')\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Un2KsjHovfj"
   },
   "source": [
    "In the visualization, all the dots are actual values and the black line represents the predicted values. The orange dots are the outliers. we see we have no outliers for this merchant transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1654519511098,
     "user": {
      "displayName": "Amy Zhuang",
      "userId": "03652318964562397937"
     },
     "user_tz": 240
    },
    "id": "gGucpnRu8GAS",
    "outputId": "f45ac600-4187-4791-86dc-698e2b6246c1"
   },
   "outputs": [],
   "source": [
    "# Visualize the anomalies\n",
    "sns.scatterplot(x='ds', y='y', data=performance, hue='anomaly')\n",
    "sns.lineplot(x='ds', y='yhat', data=performance, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT26htlqgXda"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU3z-diqgbIq"
   },
   "source": [
    "we made time series anomaly detection using Prophet in Python. The results look good for the one choosen merchant case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R56gMfflvua"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHDWii_1qQfw"
   },
   "source": [
    "[1] [Prophet Documentation](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1JzuBXS7F0Tu9Nc_WKz91_BCnhIgOBuXU",
     "timestamp": 1666879898477
    },
    {
     "file_id": "1prkJ5EkjmW3IhuAPD-jNSH8khv0j2C8t",
     "timestamp": 1666879883021
    },
    {
     "file_id": "1_ct3SFOb_RBMAx1G496h1cKd_FOXyJlH",
     "timestamp": 1654516106264
    },
    {
     "file_id": "1Q10bzMzxQLjo7Ltrd3pqJJEsMAKU3vi3",
     "timestamp": 1653007173680
    }
   ]
  },
  "kernelspec": {
   "display_name": "six_project",
   "language": "python",
   "name": "six_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
